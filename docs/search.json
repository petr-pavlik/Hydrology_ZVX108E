[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ZVX108E Hydrology",
    "section": "",
    "text": "Introduction\nThe ZVX108E Hydrology taught at the Czech University of Life Sciences is an introductory undergraduate course with students of various scientific background, many of whom do not possess knowledge of any programming language yet. Therefore we introduce within the sessions the R programming language, which serves for decades as a great tool for scientific data processing, statistical evaluation, visualization and reporting. The choice of R over other tools (like Matlab, Python or Julia) is opinionated. R is told to be “developed by statisticians for statisticians” and such as fits well into the workflow of hydrological data processing, which in most of scenarios start with some statistical analysis. We believe that the language is more straightforward to learn than others, especially non-programmers and does not maim a student’s workflow with plethora of environments and mutually incomparable versions.\nSince the course only contains six practical sessions, oriented to various parts of hydrology, we focus on the basic and merit. The book starts with a fairly fast-paced introduction to R language and it is due to this, that it did not end far from it. We purposefully avoid using what is considered a modern approach in data workflow (mainly with the help from tidyverse & data.table) as well using native pipe |&gt; operator, a syntactical feature from (R&gt;=4.1.0) which we consider too big of a change of the programming paradigm for a newbie.\nThis text was created with the use of 4.3.0 and namespaces of following packages:\n\n\n            Version\nbase          4.3.0\ncli           3.6.1\ncompiler      4.3.0\ndatasets      4.3.0\ndigest       0.6.33\nevaluate       0.23\nfastmap       1.1.1\nglue          1.6.2\ngraphics      4.3.0\ngrDevices     4.3.0\nhtmltools     0.5.7\nhtmlwidgets   1.6.2\njsonlite      1.8.7\nknitr          1.45\nlifecycle     1.0.4\nmagrittr      2.0.3\nmethods       4.3.0\nrlang         1.1.2\nrmarkdown      2.25\nrstudioapi   0.15.0\nstats         4.3.0\nstringi       1.8.1\nstringr       1.5.1\ntools         4.3.0\nutils         4.3.0\nxfun           0.41\n\n\nReproduction of all the materials should be possible using the same versions."
  },
  {
    "objectID": "01_R.html#r-as-scientific-calculator",
    "href": "01_R.html#r-as-scientific-calculator",
    "title": "1  Introduction to R language",
    "section": "1.1 R as scientific calculator",
    "text": "1.1 R as scientific calculator\n\nArithmetic operations\n\n\nCode\n1 + 2           # addition\n## [1] 3\n1 - 2           # subtraction \n## [1] -1\n1 / 2           # division\n## [1] 0.5\n1 * 2           # multiplication\n## [1] 2\n1 %/% 2         # integer division\n## [1] 0\n1 %% 2          # modulo oprator\n## [1] 1\n\n\n\n\nSpecial values\nR is familiar with the concept of \\(\\pm\\infty\\), hence -Inf and Inf values are at disposal. You will get them most probably as results from computation heading to \\(\\frac{\\pm1}{0}\\) numerically. There are other special values like NULL (null value), NA (not assigned) and NaN (not a number). The concept of not assigned is one that is particularly important, since it has significant impact on the computed result ({(code-mean-rm?)}).\n\n\nCode\nx &lt;- seq(1:10)             # general sequence of numbers\nx[c(5,6)] &lt;- NA            # change some elements to not assigned\nprint(x)\n\n\n [1]  1  2  3  4 NA NA  7  8  9 10\n\n\nCode\nmean(x)                    # without removal\n\n\n[1] NA\n\n\nCode\nmean(x, na.rm = TRUE)      # and with removal\n\n\n[1] 5.5\n\n\n\n\nSet operations\nFor manipulating sets, there are a couple of essential functions union(), intersect(), setdiff() and operator %in%.\n\n\nCode\nset_A &lt;- c(\"a\", \"a\", \"b\", \"c\", \"D\")\nset_B &lt;- c(\"a\", \"b\", \"d\")\nunion(set_A, set_B)\n## [1] \"a\" \"b\" \"c\" \"D\" \"d\"\nintersect(set_A, set_B)\n## [1] \"a\" \"b\"\nset_A %in% set_B\n## [1]  TRUE  TRUE  TRUE FALSE FALSE\n\n\n\n\nMatrix operations\nFor the purpose of following examples let’s use an arbitrary matrix \\(M\\) and a vectors \\(U\\) and \\(V\\).\n\\[\n\\mathbf{A} = \\left(\\begin{matrix}\n2x& - 3y& &= 3\\\\\n& - 2y& + 4z &= 9\\\\\n2x& + 13y& + 9z&= 10\n\\end{matrix}\\right),\\\\\n\\tag{1.1}\\]\n\\[\n\\mathbf{u} = \\begin{pmatrix}\n1\\\\\n-3\\\\\n8\\\\\n\\end{pmatrix},\n\\mathbf{v} = \\begin{pmatrix}\n1\\\\\n-3\\\\\n8\\\\\n\\end{pmatrix}\n\\tag{1.2}\\]\nSolving a system of linear equations {Equation 1.1} is a one-liner:\n\n\nCode\nA &lt;- matrix(data = c(2, -3, 0, 0, -2, 4, 2, 13, 9), nrow = 3, byrow = TRUE)\nB &lt;- c(3, 9, 10)\nsolve(A, B)\n\n\n[1]  0.5304878 -0.6463415  1.9268293"
  },
  {
    "objectID": "01_R.html#r-as-programming-language",
    "href": "01_R.html#r-as-programming-language",
    "title": "1  Introduction to R language",
    "section": "1.2 R as programming language",
    "text": "1.2 R as programming language\n\n1.2.1 Variables and name conventions\nIt is possible. We highly discourage using diacritical marks in naming, like the Czech translation of the term “variable” - proměnná. Most programmers use either camelNotation or snake_notation for naming purposes. Obviously the R is case-sensitive so camelNotation and CamelNotation are two different things. Variables do not contain spaces, quotes, arithmetical, logical nor relational operators neither they contain special characters like =, -, ``.\n\n\n1.2.2 Functions\nYou can define own functions using the function() construct. If you work in ****RStudio, just type fun and tabulate a snippet from the IDE help. The action produces {(code-function-snippet?)}.\n\n\nCode\nname &lt;- function(variables) {\n  ...\n}\n\n\nname is the name of the function we would like to create and variables are the arguments of that function. Space between the {and } is called a body of a function and contains all the computation which is invoked when the function is called.\nLet’s put Here an example of creating own function to calculate weighted mean\n\\[\n\\bar{x} = \\dfrac{\\sum\\limits_{i=1}^{n} w_ix_i}{\\sum\\limits_{i=1}^{n}w_i},\n\\] where \\(x_iw_i\\) are the individual weighted measurements.\nWe define a simple function for that purpose and run an example.\n\n\nCode\nw_mean &lt;- function(x, w = 1/length(x)) {\n  sum(x*w)/sum(w)\n}\nw_mean(1:10)\n\n\n[1] 55\n\n\nWe can test if we get the same result as the primitive function from R using all.equal() statement.\n\n\nCode\nall.equal(w_mean(x = 1:5, w = c(0.25, 0.25, 1, 2, 3)), \n          weighted.mean(x = 1:5, w = c(0.25, 0.25, 1, 2, 3)))\n\n\n[1] TRUE\n\n\nAny argument without default value in the function definition has to be provided on function call. You can frequently see functions with the possibility to specify ... a so-called three dot construct or ellipsis. The ellipsis allows for adding any number of arguments to a function call, after all the named ones.\n\n\n1.2.3 Data types\nThe basic types are logical, integer, numeric, complex, character and raw. There are some additional types which we will encounter like Date. Since R is dynamically typed, it is not necessary for the user to declare variables before using them. Also the type changes without notice based on the stored values, where the chain goes from the least complex to the most. The summary is in the following table\n\n\nCode\nTRUE    # logical, also T as short version\n## [1] TRUE\n1L      # integer\n## [1] 1\n1.2     # numeric\n## [1] 1.2\n1+3i    # complex\n## [1] 1+3i\n\"A\"     # character, also 'A'\n## [1] \"A\"\n\n\n\n\n1.2.4 Data structures\n\nVectors\nAtomic vectors are single-type linear structures. They can contain elements of any type, from logical, integer, numeric, complex, character.\n\n\nCode\n```{r}\n#| label: test-code-annotation\nV &lt;- vector(mode = \"numeric\", length = 0) # empty numeric vector creation\nV[1] &lt;- \"A\"\n```\n\n\n\n\nMatrices and arrays\nIf the object has more than one dimension, it is treated as an array. A special type of array is a matrix. Both object types have accompanying functions like colSums(), rowMeans().\n\n\nCode\nM &lt;- matrix(data = 0, nrow = 5, ncol = 2) # empty matrix creation\nM[1, 1] &lt;- 1                              # add single value at origin\nM[, 1] &lt;- 1.5                             # store 1.5 to the whole first column\nM[c(1,3), 1:2] &lt;- rnorm(2)                # store random numbers to first two rows\n\ncolMeans(M) \n## [1] 1.1298583 0.2298583\nrowSums(M)\n## [1] 0.6203801 1.5000000 1.6782029 1.5000000 1.5000000\n\n\nIt is possible to have matrices containing any data type, e.g.\n\\[\nM = \\left(\\begin{matrix}\n\\mathrm{A} & \\mathrm{B}\\\\\n\\mathrm{C} & \\mathrm{D}\n\\end{matrix}\\right),\\qquad\nN = \\left(\\begin{matrix}\n1+i & 5-3i\\\\\n10+2i & i\n\\end{matrix}\\right)\n\\]\n\n\nData frames\ndata.frame structure is the workhorse of elementary data processing. It is a possibly heterogenic table-like structure, allowing storage of multiple data types (even other structures) in different columns. A column in any data frame is called a variable and row represents a single observation. If the data suffice this single condition, we say they are in tidy format. Processing tidy data is a big topic withing the R community and curious reader is encouraged to follow the development in tidyverse package ecosystem.\n\n\nCode\nthaya &lt;- data.frame(date = NA, \n                    runoff = NA, \n                    precipitation = NA) # new empty data.frame with variables 'date', 'runoff', 'precipitation' and 'temperature'\n#thaya$runoff &lt;- rnorm(100, 1, 2)\n\n\n\n\nLists\nList is the most general basic data structure. It is possible to store vectors, matrices, data frames and also other lists within a list. List structure does not pose any limitations on the internal objects lengths.\n\n\nCode\nl &lt;- list() # empty list creation \nl[\"A\"] &lt;- 1\nprint(l)\n\n\n$A\n[1] 1\n\n\nCode\nl$A &lt;- 2\nprint(l)\n\n\n$A\n[1] 2\n\n\n\n\nOther objects\nAlthough R is intended as functional programming language, more than one object oriented paradigm is implemented in the language. As new R users we encounter first OOP system in functions like summary and plot, which represent so called S3 generic functions. We will further work with S4 system when processing geospatial data using proxy libraries like sf and terra. The OOP is very complex and will not be further discussed within this text. For further study we recommend OOP sections in Advanced R by Hadley Wickham.\n\n\n\n1.2.5 Conditions\nA condition in code creates branching of computation. Placing a condition creates at least two options from which only one is to be satisfied. The condition is created either by if()/ifelse() or switch() construct. We can again call for a snippet from RStudio help resulting in\n\n\nCode\nif (condition) {\n  ...\n}\n\nswitch (object,\n  case = action\n)\n\nifelse(test, TRUE, FALSE)\n\n\nThe condition can be branched to larger structures like\n\n\nCode\ntemperature &lt;- 30\nif (temperature &gt; 30) {\n  cat(\"The temperature is hot.\")\n} else if (temperature &gt; 15) {\n  cat(\"The temperature is warm.\")\n}\n\n\nThe temperature is warm.\n\n\n\n\n1.2.6 Repetition\nLoops (cycles) provide use with the ability to execute single statement of a block of code in {} multiple times. There are three key words for loop construction. They differ in use cases.\n\n1.2.6.1 for cycle\nProbably the most common loop is used when you know the number of iterations prior to calling. The iteration is therefore explicitly finite.\n\n\nCode\nfor (variable in vector) {\n  ...\n}\n\n\nAn example\n\n\nCode\nfor(i in 1:4) cat(i, \". iteration\", \"\\n\", sep = \"\")\n\n\n1. iteration\n2. iteration\n3. iteration\n4. iteration\n\n\n\n\n1.2.6.2 while cycle\nwhile is used in when it is impossible to state how many times something should be repeated. The case is rather in the form while some condition is or is not met, repeat what is inside the body. It is also used in intentionally infinite loop e.g. operating systems.\n\n\n1.2.6.3 repeat cycle\nIn the cases when we need the repetition at least once, we will evaluate the code inside until a condition is met.\n\n\nCode\nrepeat({\n  x &lt;- rnorm(1)\n  cat(x)\n  if(x &gt; 0) break\n})\n\n\n0.2798882\n\n\n\n\n1.2.6.4 break and next\nThere are two statements which controls the iteration flow. Anytime break is called, the rest of the body is skipped and the loop ends. Anytime next is called, the rest of the body is skipped and next iteration is started.\n\n\nI would like to have text here\nSentence becomes longer, it should automatically stay in their column\n\n\n\nand here\nMore text\n\n\n\n\n\n1.2.7 Exercise\n\ncreate a sequence of numbers calling\nWhat type is NA, why would you say is it?"
  },
  {
    "objectID": "02_statistics.html#exploratory-data-analysis-eda",
    "href": "02_statistics.html#exploratory-data-analysis-eda",
    "title": "2  Statistical processing of hydrological dataset",
    "section": "2.1 Exploratory Data Analysis (EDA)",
    "text": "2.1 Exploratory Data Analysis (EDA)\nEDA is not a strictly formalized set of procedures, rather it is an general approach on how to study, describe, extract, evaluate and report about the data. Hence the workflow is specific to data in process.\nWhen studying data, we will look at certain statistical features, which represent esteemed characteristcs for the whole data set.\n\n2.1.1 Measures of location\nThe farthest one can reduce data, while still retaining any information at all is by a single value. They describe a central tendency of the data.\n\n2.1.1.1 Mean\nThe arithmetic mean (or average) is simply the sum of observations devided by the number of observations.\n\\[\n\\text{mean} = \\dfrac{\\text{sum of data}}{\\text{number of data}}, \\qquad \\bar{x} = \\dfrac{1}{n}\\sum\\limits_{i=1}^{n} x_i\n\\]\n\n\nCode\nset.seed(123) # using the set seed will ensure that we will get the samme generated numbers every time\nx &lt;- rnorm(n = 30, mean = 50, sd = 10) # some random-generated numbers from the normal distribution\nx\n##  [1] 44.39524 47.69823 65.58708 50.70508 51.29288 67.15065 54.60916 37.34939\n##  [9] 43.13147 45.54338 62.24082 53.59814 54.00771 51.10683 44.44159 67.86913\n## [17] 54.97850 30.33383 57.01356 45.27209 39.32176 47.82025 39.73996 42.71109\n## [25] 43.74961 33.13307 58.37787 51.53373 38.61863 62.53815\n\n\n\n\n2.1.1.2 Median\nThe median is another central tendency based on the sorted data set. It is the \\(50\\)th quantile in the data. A half of the values is smaller than median, and a half is larger.\n\\[\n\\tilde{x} =\n\\]\n\n\nCode\nmedian(x)\n## [1] 49.26267\n(sort(x)[length(x)/2] + sort(x)[length(x)/2 + 1])/2\n## [1] 49.26267\n\n\n\n\n2.1.1.3 Mode\nFor continuous variables in real numbers, computation of modus does make sense when applied on bins of values.\n\n\nCode\nx\n\n\n [1] 44.39524 47.69823 65.58708 50.70508 51.29288 67.15065 54.60916 37.34939\n [9] 43.13147 45.54338 62.24082 53.59814 54.00771 51.10683 44.44159 67.86913\n[17] 54.97850 30.33383 57.01356 45.27209 39.32176 47.82025 39.73996 42.71109\n[25] 43.74961 33.13307 58.37787 51.53373 38.61863 62.53815\n\n\nCode\ncut(x, breaks = 10)\n\n\n [1] (41.6,45.3] (45.3,49.1] (64.1,67.9] (49.1,52.9] (49.1,52.9] (64.1,67.9]\n [7] (52.9,56.6] (34.1,37.8] (41.6,45.3] (45.3,49.1] (60.4,64.1] (52.9,56.6]\n[13] (52.9,56.6] (49.1,52.9] (41.6,45.3] (64.1,67.9] (52.9,56.6] (30.3,34.1]\n[19] (56.6,60.4] (41.6,45.3] (37.8,41.6] (45.3,49.1] (37.8,41.6] (41.6,45.3]\n[25] (41.6,45.3] (30.3,34.1] (56.6,60.4] (49.1,52.9] (37.8,41.6] (60.4,64.1]\n10 Levels: (30.3,34.1] (34.1,37.8] (37.8,41.6] (41.6,45.3] ... (64.1,67.9]\n\n\nCode\ny &lt;- cut(x, breaks = seq(from = -10, to = 100, by = 10))\ntable(y)\n\n\ny\n (-10,0]   (0,10]  (10,20]  (20,30]  (30,40]  (40,50]  (50,60]  (60,70] \n       0        0        0        0        6        9       10        5 \n (70,80]  (80,90] (90,100] \n       0        0        0 \n\n\nCode\nbarplot(height = table(y))\n\n\n\n\n\n\n\n2.1.1.4 \\(n-\\)th quantile\n\n\nCode\nquantile(x, probs = c(0.1, 0.9))\n\n\n     10%      90% \n38.49171 62.84304 \n\n\n\n\n\n2.1.2 Measures of spread (variability)\nWith measures of variability we describe the spread of the data around its central tendency. Some degree of variability is a natural occurring phenomenon.\n\n2.1.2.1 Variation range\nThe simples measure of spread is the variation range. It is computed as the difference of both end extremes of the data.\n\\[\nR = \\max{x} - \\min{x}\n\\]\n\n\nCode\nmax(x) - min(x)\n\n\n[1] 37.5353\n\n\n\n\n2.1.2.2 Variance\nWe calculate the variance as the average of the squares of the deviations of individual character values from their arithmetic mean.\n\\[\n\\sigma^2 = \\frac{1}{n}(x_i - \\bar{x})^2\n\\]\n\n\n2.1.2.3 Standard deviation\nThe standard deviation is defined as sqruare root of variance.\n\n\nCode\nsd(x)\n## [1] 9.810307\nvar(x)^0.5\n## [1] 9.810307\n\n\n\n\n2.1.2.4 Coefficient of variation\nThe coefficient of variation is given by the ratio of the standard deviation and the arithmetic mean, and it follows from the definition of this ratio that it is a dimensionless indicator.\n\\[\n\\nu = \\frac{s}{\\bar{x}}\n\\]\n\n\n2.1.2.5 Interquartile range\nThe \\(\\text{IQR}\\) is the upper quartile (\\(75\\)th percentile) minus the lower quartile (\\(25\\)th percentile)\n\\[\n\\text{IQR} = Q_{\\text{III}} - Q_{\\text{I}}\n\\]\n\n\nCode\nIQR(x)\n\n\n[1] 11.60016"
  },
  {
    "objectID": "02_statistics.html#hydrological-data",
    "href": "02_statistics.html#hydrological-data",
    "title": "2  Statistical processing of hydrological dataset",
    "section": "2.2 Hydrological data",
    "text": "2.2 Hydrological data\nData sets containing hydrological data are most commonly, although not exclusively, in tabular (rectangular) shape. Let’s take a look at sample data from MOOPEX. It is a simple curated large sample data set.\nThis dataset covers the same 438 catchments in daily step with measured discharge. The dataset is publicly available at https://hydrology.nws.noaa.gov/pub/gcip/mopex/US_Data/Us_438_Daily/\n\n\nCode\nurl &lt;- \"./data/01138000.dly\"\nmpx &lt;- read.fwf(file = url, \n                widths = c(8, rep(10, times = 5)), \n                header = FALSE)\nnames(mpx) &lt;- c(\"date\", \"prec\", \"pet\", \"r\", \"tmax\", \"tmin\")\nmpx$date &lt;- gsub(x = mpx$date, pattern = \" \", replacement = \"0\")\nmpx$date &lt;- as.Date(mpx$date, format = \"%Y%m%d\")\nmpx[which(mpx$r &lt; 0), \"r\"] &lt;- NA \nhead(mpx)\n##         date prec   pet      r    tmax     tmin\n## 1 1948-01-01 0.00 0.080 0.2620 -2.9167 -11.2556\n## 2 1948-01-02 4.44 0.081 0.2501 -2.9556 -11.8500\n## 3 1948-01-03 4.74 0.081 0.2501 -0.1778  -5.6444\n## 4 1948-01-04 0.00 0.081 0.2620 -1.8778  -4.2222\n## 5 1948-01-05 0.00 0.083 0.2501  0.8778  -4.3389\n## 6 1948-01-06 1.78 0.084 0.2620 -0.2889  -5.4833\n\n\nLet’s add some features to the data. For the purpose of the analysis it would be beneficial to add year, month, quarters, decade and hyear as hydrological year."
  },
  {
    "objectID": "02_statistics.html#aggregation-and-summation",
    "href": "02_statistics.html#aggregation-and-summation",
    "title": "2  Statistical processing of hydrological dataset",
    "section": "2.3 Aggregation and summation",
    "text": "2.3 Aggregation and summation\n\n\nCode\nmpx$year &lt;- as.integer(format(mpx$date, \"%Y\"))\nmpx$month &lt;- as.integer(format(mpx$date, \"%m\"))\n\n\nTry to add quart variable using quarters() function.\n\n\nCode\nmpx$hyear &lt;- ifelse(mpx$month &gt; 10, as.integer(mpx$year + 1), as.integer(mpx$year))\n\n\nNow exercise some basic calculations\n\nFraction of days with no precipitation\nHow many freezing days occur?\nHow many freezing days in late spring (May) and summer?\n10 highest and 10 lowest temperatures\n\nThese functions are based on grouping. In hydrology, the natural groups involve - stations/basins, decades/years/months, groundwater regions, etc.\n\n2.3.1 Box-plot\nCome handy, when we want to visualize the important quantiles related to any categorical variable.\n\n\nCode\nstation &lt;- read.delim(\"./data/6242910_Q_Day.Cmd.txt\", skip = 36, header = TRUE, sep = \";\", col.names = c(\"date\", \"time\", \"value\"))\nstation$date &lt;- as.Date(station$date, format = \"%Y-%m-%d\")\n\nstation_agg &lt;- aggregate(station$value ~ as.factor(data.table::month(station$date)), \n                         FUN = \"quantile\", \n                         probs = c(0.1, 0.25, 0.5, 0.75, 0.9))\nnames(station_agg) &lt;- c(\"Month\", \"Discharge\")\npar(font.main = 1, \n    adj = 0.1, \n    xaxs = \"i\", \n    yaxs = \"i\")\nboxplot(data = station_agg, \n        Discharge ~ Month, \n        main = \"Distribution of discharge in months\", \n        frame = FALSE, \n        ylim = c(0,20), \n        xlab = \"\", \n        ylab = bquote(Discharge), font.main = 1)\n\n\n\n\n\n\n\n2.3.2 Q-Q plot\nThe so called rankit graph produces a quantile-quantile graph of the values from selected data. This one can compare if the distribution of the data fit with the assumed distribution, e.q. Normal. qqline then adds the theoretical line, which outputs\n\n\nCode\npar(font.main = 1, \n    adj = 0.1, \n    xaxs = \"i\", \n    yaxs = \"i\")\nqqnorm(mpx$tmax, \n       pch = 21, \n       col = \"black\", \n       bg = \"lightgray\", cex = 0.5, \n       main = \"\")\nqqline(mpx$tmax)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.3 Empirical distribution function\nLarge portion of the data which is processed in Hydrology originates from time series of streamflow or runoff. This enables us to construct empirical probability of exceeding certain value in the data \\(P(X\\geq x_k)\\), simply using the well know definition\n\\[\nP = \\dfrac{m}{n}\n\\] where \\(m\\) is the number of reaching or exceeding of value \\(x_k\\) and \\(n\\) is the length of the series. This equation is valid strictly for \\(n \\rightarrow \\infty\\).\nThere are several empirical formulas in use to calculate the empirical exceedance probability like the one from Čegodajev\n\\[\nP = \\dfrac{m - 0.3}{n + 0.4}\n\\] In R we can utilize a highe order function called ecdf()\n\n\nCode\n1ecdf_data &lt;- ecdf(na.omit(mpx$r))\nmax(mpx$r, na.rm = TRUE)\necdf_data(35) # percent of data lower than 35\n\n\n\n1\n\nCreate the empirical cumulative distribution function (ECDF) for the data\n\n\n\n\n[1] 35.7248\n[1] 0.9998328\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.4 Exceedance curve\n\n\nCode\nr_sorted &lt;- sort(mpx$r, decreasing = TRUE)\n\n# Empirical\nn &lt;- length(r_sorted)\nexceedance_prob &lt;- 1:n / n\n\nplot(exceedance_prob, r_sorted, type = \"l\", xlab = \"Exceedance Probability\", ylab = \"Runoff Value\", main = \"Empirical Exceedance Curve\")\n\n\n\n\n\n\n\n2.3.5 Return period\nWe calculate the return period as inverse to the exceedance probability\n\n\nCode\nreturn_period &lt;- 1/exceedance_prob \n\nplot(return_period, r_sorted, type = \"l\", xlab = \"Return Period\", ylab = \"Runoff Value\", main = \"Empirical Return Period\")"
  },
  {
    "objectID": "02_statistics.html#hydrological-indices",
    "href": "02_statistics.html#hydrological-indices",
    "title": "2  Statistical processing of hydrological dataset",
    "section": "2.4 Hydrological indices",
    "text": "2.4 Hydrological indices\nOriginated from the combination of aggregation and summation methods and the measures of location and dispersion.\n\n2.4.1 Runoff coefficient\nThe concept of runoff coefficient comes from the presumption, that over long-time period\n\\[\n\\varphi [-] = \\dfrac{R}{P}\n\\] where \\(R\\) represents runoff and \\(P\\) precipitation in long term, typically 30 year so called Normal period, which is a decadal moving 30 window; the current being 1991–2020.\n\n\nCode\nR &lt;- mean(aggregate(r ~ year, FUN = mean, data = mpx)[, \"r\"])\nP &lt;- mean(aggregate(prec ~ year, FUN = mean, data = mpx)[, \"prec\"])\n\nR/P\n\n\n[1] 0.493947\n\n\n\n\n2.4.2 Flow duration curve\n\n\nCode\nM &lt;- c(30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330, 355, 364)\nm_day &lt;- function(streamflow) {\n  quantile(na.omit(streamflow), 1 - M/365.25)\n}\nplot(M, m_day(mpx$r), \n     type = \"b\", \n     pch = 21,\n     bg = \"darkgray\",\n     xlab = \"\", \n     ylab = \"Discharge\", \n     main = \"M-day discharge\")\n\n\n\n\n\n\n\n2.4.3 Baseflow\nThe Total runoff comprises from direct runoff, hypodermic runoff and baseflow. From the baseflow separation process usually the baseflow index is calculated \\(\\text{BFI}=\\dfrac{\\text{baseflow}}{\\text{total runoff}}\\)"
  },
  {
    "objectID": "03_gis.html#whiteboxtools",
    "href": "03_gis.html#whiteboxtools",
    "title": "3  GIS in Hydrology",
    "section": "3.1 WhiteboxTools",
    "text": "3.1 WhiteboxTools\nIn this session we use the WhiteboxTools (WBT) a modern and advanced geospatial package, tools collection, which contains ~450 functions. The WBT has an interface to r and python.\nThe tool can be downloaded from http://whiteboxgeo.com/."
  },
  {
    "objectID": "03_gis.html#raster-and-vector-data",
    "href": "03_gis.html#raster-and-vector-data",
    "title": "3  GIS in Hydrology",
    "section": "3.2 Raster and vector data",
    "text": "3.2 Raster and vector data\nRaster data are represented by a matrix of pixels (cells) with values. Raster is used for data which display continuous information across an area which cannot be easily divided into vector features. For the purpose of watershed delineation the raster input of Digital Elevation Model is used."
  },
  {
    "objectID": "03_gis.html#watershed-delineation",
    "href": "03_gis.html#watershed-delineation",
    "title": "3  GIS in Hydrology",
    "section": "3.3 Watershed delineation",
    "text": "3.3 Watershed delineation\nThe process of delineation is the first step in basin description. One simply has to delineate the domain\nThe step-by-step process involves:\n\n\nacquiring digital elevation model of area\n\npit and sink removal\n\nflow accumulation calculation\n\nflow direction calculation\n\noutlet identification\n\ndelineation towards specified outlet\n\n\nLet’s start with whitebox package that contains an API to the WhiteboxTools executable binary.\nWe need to reference path to the executable\nExcept for the whitebox package, some other packages for general work with spatial data are necessary. The packages terra and sf are needed for working with the raster and vector data. They also provide access to PROJ, GEOS and GDAL which are open source libraries that handle projections, format standards and provide geoscientific calculations. And the package tmap makes plotting both raster and vector layers very easy."
  },
  {
    "objectID": "03_gis.html#geostatistics",
    "href": "03_gis.html#geostatistics",
    "title": "3  GIS in Hydrology",
    "section": "3.5 Geostatistics",
    "text": "3.5 Geostatistics\n\n\nCode\nwbt_jenson_snap_pour_points(pour_pts = paste(wd_path, \"gauge/gauge.shp\", sep = \"/\"), \n                            streams = paste(wd_path, \"streams.tif\", sep = \"/\"), \n                            output = paste(wd_path, \"gauge_snapped.shp\", sep = \"/\"), \n                            snap_dist = 1000)\n\n\n\n\nCode\nwbt_watershed(d8_pntr = paste(wd_path, \"d8pointer.tif\", sep = \"/\"),\n              pour_pts = paste(wd_path, \"gauge_snapped.shp\", sep = \"/\"), \n              output = paste(wd_path, \"watershed.tif\", sep = \"/\"))\n\n\n\n3.5.1 River morphology statistics\nUnder the term river morphology we understand the description of the shape of river channels. Hydrologists use indices such as stream length, Strahler order"
  },
  {
    "objectID": "03_gis.html#session",
    "href": "03_gis.html#session",
    "title": "3  GIS in Hydrology",
    "section": "3.6 Session",
    "text": "3.6 Session\n\nStart with downloading DEM of specified area."
  },
  {
    "objectID": "03_gis.html#watershed-delineation-workflow",
    "href": "03_gis.html#watershed-delineation-workflow",
    "title": "3  GIS in Hydrology",
    "section": "3.4 Watershed delineation workflow",
    "text": "3.4 Watershed delineation workflow\n\n\nCode\n1library(whitebox)\n2library(terra)\n## terra 1.7.55\n3library(sf)\n## Linking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n4library(tmap)\n## Breaking News: tmap 3.x is retiring. Please test v4, e.g. with\n## remotes::install_github('r-tmap/tmap')\n5whitebox::wbt_init(exe_path = \"~/Downloads/WBT/whitebox_tools\")\n6whitebox::check_whitebox_binary()\n## [1] TRUE\n\n\n\n1\n\nLoad the Whitebox API package\n\n2\n\nLoad the terra package for raster use\n\n3\n\nLoad the sf package for vector use\n\n4\n\nLoad the tmap plotting functions for layers\n\n5\n\nWhitebox needs the information where the data executable is stored\n\n6\n\nBinary check of functionality\n\n\n\n\n\n3.4.0.1 Sample data\n\n\nCode\n1dem &lt;- rast(whitebox::sample_dem_data())\n2tm_layout(legend.outside = TRUE) +\n  tm_shape(dem) +\n  tm_raster(palette = \"-Greys\", n = 50)\n\n\n\n1\n\nUse the rast() function to load the data\n\n2\n\nPlot via the tmap workflow\n\n\n\n\n\n\n\n\n\n3.4.0.2 DEM workflow\nThe digital elevation model has to be adjusted for the watershed delineation algorithm to be able to run successfully.\n\n\nCode\nwd_path &lt;- \"~/Desktop/GIS\"\nwbt_fill_depressions_wang_and_liu(dem = paste(wd_path, \n                                              \"dem.tif\", \n                                              sep = \"/\"), \n                                  output = paste(wd_path, \n                                                 \"filled_depresions.tif\", \n                                                 sep = \"/\"))\n\nwbt_d8_pointer(dem = paste(wd_path, \n                           \"filled_depresions.tif\", \n                           sep = \"/\"), \n               output = paste(wd_path, \n                              \"d8pointer.tif\", \n                              sep = \"/\"))\n\nwbt_d8_flow_accumulation(input = paste(wd_path, \n                                       \"filled_depresions.tif\", \n                                       sep = \"/\"),\n                         output = paste(wd_path, \n                                        \"flow_accu.tif\", \n                                        sep = \"/\"), \n                         out_type = \"cells\")\n\nwbt_extract_streams(flow_accum = paste(wd_path, \n                                       \"flow_accu.tif\", \n                                       sep = \"/\"), \n                    output = paste(wd_path, \n                                   \"streams.tif\", \n                                   sep = \"/\"), \n                    threshold = 200)\n\n\n\n\n3.4.1 Gauge\nWe have the raster prepared for the delineation, now we need to provide a point layer with the gauge, to which the watershed should be delineated. The point has to be placed at the stream network. We will create the layer from scratch.\n\n\nCode\nst_write(obj = st_sfc(st_point(x = c(671035, 4885783), \n                               dim = \"XY\"), \n                      crs = st_crs(26918)), \n         dsn = paste(wd_path, \"gauge\", sep = \"/\"), driver = \"ESRI Shapefile\")\n\n\n\n\nCode\ntm_layout() +\n  tm_shape(dem) +\n  tm_raster() +\n  tm_shape(gauge) +\n  tm_dots(col = \"red\", size = 2)"
  }
]